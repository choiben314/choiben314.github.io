<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Acoustic Imaging</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/themes/prism-tomorrow.min.css" />
    <link rel="stylesheet" href="acoustic.css" />
  </head>
  <body>
    <div class="wrap">
      <header>
        <div class="meta">
          <span class="tag">Draft</span>
        </div>
        <h1>48‑Channel Acoustic Imaging</h1>
        <p class="author">Ben Choi</p>
        <p class="lead">
          From microphone PDM capture on Colorlight 5a-75B FPGA, through UDP transport and
          host‑side decimation, to frequency‑domain cross‑correlation and 3D
          geometry optimization.
        </p>
      </header>

      <nav class="toc">
        <strong>Sections</strong>
        <a href="#overview">Overview</a> · <a href="#hardware">Hardware</a> ·
        <a href="#fpga">FPGA PDM → UDP</a> ·
        <a href="#capture">Host Capture & Ring</a> ·
        <a href="#cic">CIC Decimation → PCM</a> ·
        <a href="#ingest">Python Ingest</a> · <a href="#gcc">GCC‑PHAT</a> ·
        <a href="#opt">3D Optimization</a> ·
        <a href="#next">Next Steps</a>
      </nav>

      <section id="overview">
        <div class="stage"><h2>Overview</h2></div>
        <p>
          The project implements a low-cost complete acoustic imaging pipeline using a
          48‑channel acoustic phased array (heavily inspired by <a href="https://benwang.dev/2023/02/26/Phased-Array-Microphone.html"
            >Ben Wang's project</a
          >):
        </p>
        <ul>
          <li>
            <strong>48 microphones</strong> arranged radially on a custom PCB,
            generating 1‑bit PDM streams.
          </li>
          <li>
            <strong>FPGA</strong> clocks and samples PDM, packs data, and
            streams via UDP using LiteEth.
          </li>
          <li>
            <strong>Host capture</strong> taps raw Ethernet via macOS
            <span class="kbd">/dev/bpf</span> and writes into a shared memory
            ring.
          </li>
          <li>
            <strong>CIC decimation</strong> converts 1‑bit PDM to multi‑channel
            PCM int32.
          </li>
          <li>
            <strong>GCC‑PHAT</strong> in the frequency domain retrieves robust
            TDOAs per frame.
          </li>
          <li>
            <strong>Nonlinear optimization</strong> (PyTorch) recovers mic
            positions, source trajectory, and speed of sound.
          </li>
        </ul>
        <div class="figure">
          <img src="img_acoustic/assembly.png" alt="Calibration plot" /><small
            >Acoustic phased array assembly</small
          >
        </div>
      </section>

      <section id="hardware">
        <div class="stage"><h2>Hardware: 48‑Mic Circular Array</h2></div>
        <p>
          The array consists of eight arms, each with three pins, and each pin
          carrying two microphones: inner (H) and outer (L). The full array
          exposes 24 stereo lines → <strong>48 channels</strong>.
        </p>
        <div class="card">
          <h3>PCB/Layout</h3>
          <p class="muted">Custom spokes + hub PCBs.</p>
          <div class="figure-row">
            <div class="figure">
              <img src="img_acoustic/hub.png" alt="Hub PCB" />
              <small>Hub</small>
            </div>
            <div class="figure">
              <img src="img_acoustic/spoke.png" alt="Spoke PCB" />
              <small>and Spoke!</small>
            </div>
          </div>
        </div>
        <p>
          On the FPGA side, we simply leverage the pin mapping from
          <a
            href="https://github.com/q3k/chubby75/blob/master/5a-75b/hardware_V8.2.md"
            >Chubby75</a
          > of the Colorlight 5a-75B board. The hardest part here was removing the 74HC245 buffer between the
          FPGA and the microphones to enable 3.3V logic inputs and soldering
          tiny flex PCBs (this took a lot of trial and error to do
          consistently).
          <div class="figure">
            <img src="img_acoustic/bypass.png" alt="FPGA Pins" /><small
              >so tiny D:</small
            >
          </div>
        </p>
      </section>

      <section id="fpga">
        <div class="stage"><h2>FPGA: PDM Sampling → UDP Payloads</h2></div>
        <p>
          On‑FPGA logic clocks the shared PDM data line per pin, sampling on
          both edges to separate inner/outer microphones. Words are emitted in
          12‑byte groups: <em>[packet_id, word_prev, word_curr]</em>, repeated
          to fill UDP payloads.
        </p>
        <pre><code class="language-python"># fpga/pdm.py — PDM capture into a 32-bit stream
class PDM(Module):
    def __init__(self, clk_pad, data):
        self.clk_pad = clk_pad
        self.source = stream.Endpoint([("data", 32)])
        count = Signal(4)      # 0..15 (rising/falling edges)
        packet_id = Signal(32)
        data_reg = Signal(24)

        # Capture around edge; emit packet_id then data words
        self.sync += If((count & 7) == 5, data_reg.eq(data))
        self.comb += self.clk_pad.eq(count[-1])  # drive PDM clock

        stmt = If((count & 15) == 0,
                  self.source.data.eq(packet_id),
                  self.source.valid.eq(1),
                  self.source.first.eq(1))
        stmt = stmt.Elif((count & 7) == 1,
                         self.source.data.eq(data_reg),
                         self.source.valid.eq(1),
                         self.source.first.eq(0))
        self.sync += stmt.Else(self.source.valid.eq(0), self.source.first.eq(0))
        self.sync += If((count & 15) == 9, self.source.last.eq(1)).Else(self.source.last.eq(0))
        self.sync += [count.eq(count + 1), If((count & 15) == 15, packet_id.eq(packet_id + 1))]
</code></pre>
        <p>
          The UDP path is built on
          <a href="https://github.com/enjoy-digital/liteeth">LiteEth</a>. See
          <code>fpga/main.py</code> for SoC instantiation and port wiring.
        </p>
      </section>

      <section id="capture">
        <div class="stage"><h2>Host Capture: macOS BPF → Shared Ring</h2></div>
        <p>
          On the host, a zero‑copy capture tool uses
          <span class="kbd">/dev/bpf</span> to parse VLAN + IPv4 + UDP, extract
          the packed 12‑byte groups, and write interleaved PCM batches into a
          memory‑mapped ring file for Python to consume.
        </p>
        <pre><code class="language-c">// beamforming/fastcap_pcm.c — ring header and write helper
struct ring_header {
    char magic[8];
    uint32_t version; uint32_t reserved0; uint64_t capacity_bytes;
    _Atomic uint64_t write_pos, read_pos, dropped_by_bpf, blocked_waits;
    uint32_t linktype; uint32_t reserved1;  // LINKTYPE_PCM
};

static void ring_write_pcm_multi(struct ring_header *hdr, uint8_t *data,
    const int32_t *interleaved, size_t frames, size_t channels,
    uint32_t ts_sec, uint32_t ts_usec) {
    // ... writes one aligned record with a small header + payload ...
}
</code></pre>

        <pre><code class="language-c">// IPv4/VLAN/UDP parsing → unpack 3x32-bit groups and feed CIC
if (parse_udp_payload_ipv4_vlan(pkt, caplen, &udp, &udp_len, udp_port)) {
    size_t num_words = udp_len / 4;
    if (num_words &gt;= 3) {
        const uint8_t *wp = udp; size_t frames = num_words / 3;
        for (size_t i = 0; i &lt; frames; i++) {
            uint32_t w_prev = *(uint32_t*)(wp + 4);
            uint32_t w_curr = *(uint32_t*)(wp + 8);
            // run CIC per line, interleave L/H; batch and commit to ring
            // ...
            wp += 12;
        }
    }
}
</code></pre>
        <p>
          Default ring path is <code>/tmp/fastcap_pcm.ring</code>, with
          <em>linktype</em> set to <code>0xFFFF</code> to denote PCM.
        </p>
      </section>

      <section id="cic">
        <div class="stage">
          <h2>CIC Decimation: 1‑bit PDM → Multichannel PCM</h2>
        </div>
        <p>
          Each line carries two PDM streams (outer/inner) captured on alternate
          edges. A parameterizable <strong>CIC</strong> (Cascaded
          Integrator‑Comb) converts the 1‑bit streams into wide dynamic‑range
          PCM.
        </p>
        <pre><code class="language-c">// beamforming/fastcap_pcm.c — 3‑stage CIC with decimation R (default 64)
typedef struct { int stages, R, decim_count; int64_t intL[8], intR[8], combL[8], combR[8]; } CIC;
static bool cic_process_bit(CIC *c, uint32_t bitL, uint32_t bitR, int32_t *outL, int32_t *outH) {
    int64_t vL = cic_integrate(bitL ? 1 : -1, c-&gt;intL, c-&gt;stages);
    int64_t vR = cic_integrate(bitR ? 1 : -1, c-&gt;intR, c-&gt;stages);
    if (++c-&gt;decim_count &lt; c-&gt;R) return false; c-&gt;decim_count = 0;
    int64_t yL = cic_comb(vL, c-&gt;combL, c-&gt;stages);
    int64_t yR = cic_comb(vR, c-&gt;combR, c-&gt;stages);
    return true;
}
</code></pre>
        <p>
          With a PDM clock of ≈3.125&nbsp;MHz and decimation <code>R=64</code>,
          the PCM rate is ≈48.828&nbsp;kHz. The decimator runs per line,
          emitting frames interleaved as <em>L1,H1,L2,H2,…,L24,H24</em>.
        </p>
      </section>

      <section id="ingest">
        <div class="stage">
          <h2>Python Ingest: Ring → WAVs</h2>
        </div>
        <p>Python readers consume the ring and write WAVs.</p>
      </section>

      <section id="gcc">
        <div class="stage"><h2>Time‑Difference Estimation: GCC‑PHAT</h2></div>
        <p>
          Frames are windowed and transformed. Generalized cross‑correlation
          with PHAT weighting produces robust TDOA estimates relative to a
          handful of reference microphones.
        </p>
        <pre><code class="language-python"># beamforming/calibration.py — GCC‑PHAT core
def gcc_phat_tdoa(frames, sample_rate, ref_indices, max_lag_s=0.004):
    T, N, C = frames.shape
    nfft = 1 &lt;&lt; (N - 1).bit_length()
    X = np.fft.rfft(frames, n=nfft, axis=1)           # (T,F,C)
    tdoa = np.zeros((T, len(ref_indices), C), np.float32)
    peak = np.zeros_like(tdoa)
    eps = 1e-12
    for ri, ref in enumerate(ref_indices):
        Xr = X[:, :, ref]
        Rxc = Xr.conj()[:, None, :] * X.transpose(0, 2, 1)
        Rxc /= (np.abs(Rxc) + eps)                     # PHAT
        corr = np.fft.irfft(Rxc, n=nfft, axis=2)
        # fftshift + local window; take argmax for TDOA per channel
        # ...
    return tdoa, peak
</code></pre>
      </section>

      <section id="opt">
        <div class="stage">
          <h2>
            Nonlinear Optimization: Mic Geometry, Source Path, Speed of Sound
          </h2>
        </div>
        <p>
          We jointly optimize microphone positions (48×3), a 3D source
          trajectory over frames, and the speed of sound. The loss penalizes
          TDOA residuals with a Huber term (reduces impact of outliers), while
          regularizing mic positions near the design, enforcing planar mics, and
          smoothing the trajectory.
        </p>
        <pre><code class="language-python"># beamforming/calibration.py — loss sketch
def loss_fn(mic_pos, src_pos, log_c, tdoa, mask, ref_indices):
    c = torch.exp(log_c)
    d = torch.linalg.norm(src_pos[:, None, :] - mic_pos[None, :, :], dim=2)
    d_ref = d[:, ref_indices]
    pred = (d[:, None, :] - d_ref[:, :, None]) / c
    valid = mask.clone();
    for ri, ref in enumerate(ref_indices):
        valid[:, ri, ref] = False
    diff = torch.where(valid, pred - tdoa, torch.zeros_like(pred))
    absd = torch.abs(diff); delta = 2e-4
    huber = torch.where(absd &lt;= delta, 0.5*(absd**2)/delta, absd - 0.5*delta)
    data = huber.sum() / valid.sum().clamp(min=1)
    reg = 5e-3*((mic_pos - mic0)**2).mean() + 2e-3*(mic_pos[:,2]**2).mean()
    return data + reg + 1e-2*jerk_reg(src_pos) + 5e-3*accel_reg(src_pos) + 1e-5*((c-343.0)**2)
</code></pre>
        <div class="tabs">
          <div class="tab-buttons">
            <button class="tab-btn active" data-tab="demo">Interactive 3D</button>
            <button class="tab-btn" data-tab="plot">Static Plot</button>
          </div>
          <div class="tab-content">
            <div class="tab-panel active" id="tab-demo">
              <iframe src="acoustic_demo.html"></iframe>
              <small>Sound source localization trajectory capture</small>
            </div>
            <div class="tab-panel" id="tab-plot">
              <img src="img_acoustic/calibration_plot.png" alt="Calibration plot" />
              <small>Output from moving white noise sound source in a spiral pattern.</small>
            </div>
          </div>
        </div>
      </section>

      <section id="next">
        <div class="stage"><h2>Next Steps</h2></div>
        <p>
          The project is a work in progress and there are many things that can
          be improved.
        </p>
        <ul>
          <li>
            Build a more rigid assembly + FPGA housing to avoid having to
            recalibrate.
          </li>
          <li>
            Move CIC decimation to FPGA and push the limits of number of
            channels we can handle on standard Gigabit Ethernet.
          </li>
          <li>
            Adjust TDOA calculation to be pairwise instead of relative to a
            reference microphone.
          </li>
        </ul>
      </section>

      <hr class="hr" />
      <footer>
        <p>
          <strong>Stack</strong>: LiteX/LiteEth, Migen, ECP5, macOS BPF, C11,
          Python/Numpy/PyTorch.
        </p>
        <p><strong>References</strong></p>
        <ul>
          <li><a href="https://benwang.dev/2023/02/26/Phased-Array-Microphone.html" target="_blank" rel="noopener">Ben Wang's Version</a></li>
          <li><a href="https://blog.yosyshq.com/p/colorlight-part-2/" target="_blank" rel="noopener">Colorlight 5a-75B Board</a></li>
          <li><a href="https://tomverbeure.github.io/2021/01/22/The-Colorlight-i5-as-FPGA-development-board.html" target="_blank" rel="noopener">Colorlight i5 Board</a></li>
          <li><a href="https://zeromips.org/posts/2022-05-29-5a-75b/" target="_blank" rel="noopener">74HC245 Bypass</a></li>
        </ul>
      </footer>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/prism-core.min.js"></script>
    <script
      src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/autoloader/prism-autoloader.min.js"
      data-autoloader-path="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/"
    ></script>
    <script>
      document.querySelectorAll('.tab-btn').forEach(btn => {
        btn.addEventListener('click', () => {
          const tab = btn.dataset.tab;
          document.querySelectorAll('.tab-btn').forEach(b => b.classList.remove('active'));
          document.querySelectorAll('.tab-panel').forEach(p => p.classList.remove('active'));
          btn.classList.add('active');
          document.getElementById('tab-' + tab).classList.add('active');
        });
      });
    </script>
  </body>
</html>
